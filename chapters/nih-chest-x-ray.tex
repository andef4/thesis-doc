\chapter{NIH Chest X-ray}
To find out what outputs the different methods generate, we started with a simple classification task in the medical image field:

\section{Training}
\subsection{Inception Resnet v2}
\begin{itemize}
    \item  chest x-ray, sample data set (small subset)
    \item  multi label classification
    \item  current state of the art networkj: inception  resetnet v2 (accurate + fast to train on single GPU) \cite{todo}
    \item  using learnings and code from project2
    \item  slightly modified inception resnet v2 implementation (grayscale instead of color)
    \item  did not work, convert to RGB and downscale images (offline, preprocess.ipynb)
    \item  results: 40\% validation accuracy => bad
    \item smaller batch size (citation needed) 5, => not better
    \item next: use full dataset
    \item download 42 gigs of data
    \item simple python multiprocessing for preprocessing
\end{itemize}

\subsection{ResNet}
Instead of waiting for the expected very long learning time for Inception-Resnet V2, we did a short test with Resnet50 with pretrained parameters (ImageNet) on the sample dataset. Only the last layer is unfreezed.

\begin{itemize}
    \item Epoch time of ~40 seconds instead of (TODO) 10 minutes/3 hours for full dataset
    \item resnet50 with pretrained
    \item resnet50 without pretrained
    \item resnet18 without pretrained
    \item resnet18 without pretrained full dataset
\end{itemize}

\subsection{Only images with actual diagnosis}
https://www.kaggle.com/kmader/train-simple-xray-cnn 
For testing out the methods, images with findings are much more helpful, so filter them out.

Better results:


\subsection{Single label only}
65\%

\subsection{Densenet}
% https://medium.com/@jrzech/reproducing-chexnet-with-pytorch-695ff9c3bf66

\subsubsection{Image resize problems}

