\chapter{NIH Chest X-ray}
To find out what outputs the different methods generate, we started with a simple classification task in the medical image field:

\section{Training}
\subsection{Inception Resnet v2}
\begin{itemize}
    \item  chest x-ray, sample data set (small subset)
    \item  multi label classification
    \item  current state of the art networkj: inception  resetnet v2 (accurate + fast to train on single GPU) \cite{todo}
    \item  using learnings and code from project2
    \item  slightly modified inception resnet v2 implementation (grayscale instead of color)
    \item  did not work, convert to RGB and downscale images (offline, preprocess.ipynb)
    \item  results: 40\% validation accuracy => bad
    \item smaller batch size (citation needed) 5, => not better
    \item next: use full dataset
    \item download 42 gigs of data
    \item simple python multiprocessing for preprocessing
\end{itemize}

\subsection{ResNet}
Instead of waiting for the expected very long learning time for Inception-Resnet V2, we did a short test with Resnet50 with pretrained parameters (ImageNet) on the sample dataset. Only the last layer is unfreezed.

\begin{itemize}
    \item Epoch time of ~40 seconds instead of (TODO) 10 minutes/3 hours for full dataset
    \item resnet50 with pretrained
    \item resnet50 without pretrained
    \item resnet18 without pretrained
    \item resnet18 without pretrained full dataset
\end{itemize}

\subsection{Only images with actual diagnosis}
https://www.kaggle.com/kmader/train-simple-xray-cnn 
For testing out the methods, images with findings are much more helpful, so filter them out.

Better results:


\subsection{Single label only}
65\%

\subsection{Densenet}
% https://medium.com/@jrzech/reproducing-chexnet-with-pytorch-695ff9c3bf66

Loading the saved model did not work, because the used version of PyTorch was old and incompatible with ours.

=> Retraining

\subsubsection{Image resize problems}
In the Densenet code there was a reference that some images were not properly resized. We did a short check on our preprocessed data, but it revelead no such problems. Used bash command:

\begin{minted}{bash}
find . -name '*.png' -exec file {} \; | cut -c 37-45 | uniq
\end{minted}
299 x 299

\subsection{Densenet single}
\begin{itemize}
    \item Fail: Not correctly setting up classes (last layer has 1000 classes for imagenet, we have 14)
    \item Fail 2: Train and validation set do not have same classes because of ordering in dataset loading code
\end{itemize}

After training for a short time with the fixes, we get an acceptable accuracy rate of 55\%. We then started to calculate the accuracy per class, as has been done on the reproduce-chexnet discussed above. We quickly discovered that only the "No findings" class was accurate, an all other classes had zero correct classifications.

\begin{itemize}
    \item test with no findings removed => not that better, finds only 3 classes correctly
    \item try with weighted cross entropy loss
\end{itemize}


\section{Methods}

\begin{tabular}{|l|l|l|}
\hline
 \textbf{Method} & \textbf{Model blackbox} & \textbf{Portable to PyTorch} \\ \hline
 RISE & Yes & Supported out of the box \\ \hline
 LIME & Yes & Easy \\ \hline
 Layer-wise Relevance Propagation (Heatmapping.org)& No & Should be possible \\ \hline
\end{tabular}

PatternNet: https://arxiv.org/pdf/1705.05598.pdf

heatmap presentation:
Baehrens'10 Gradient
Sundarajan'17 Int Grad
Zintgraf'17 Pred Diff
Ribeiro'16 LIME
Haufe'15 Pattern
Symonian'13 Gradient
Zeiler'14 Occlusions
Fong'17 M Perturb
Zurada'94 Gradient
Poulin'06 Additive
Zeiler'14 Deconv
Lundberg'17 Shapley
Landecker'13 Contrib Prop
Caruana'15 Fitted Additive
Bazen'13 Taylor
Springenberg'14 Guided BP
Montavon'17 Deep Taylor
Bach'15 LRP
Zhou'16 GAP
Kindernnans'17 PatternNet
Shrikumar'17 DeepLIFT
Zhang'16 Excitation BP
Selvaraju'17 Grad-CAM
