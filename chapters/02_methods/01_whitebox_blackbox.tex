\section{White box and black box methods}
Generally there are two types of methods for interpretability: Black box and white box. White box methods need access to the neural network parameters (weights, biases etc.) and/or the individual activations of neurons inside the networks when an image is processed by it. Some white box methods only work with the network parameters itself, others explain the network output for specific sample inputs.

Black box methods only work with the input (e.g. images) and the output (e.g. classes) of a neural network and can be used on arbitrary network architectures and even non-deep learning technologies like decision trees. Black box methods only work with specific sample inputs and cannot analyze the network in a general way.
